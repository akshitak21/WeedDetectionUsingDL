{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b407ez1DgIW7",
        "outputId": "f26c633b-5e94-429a-9eb7-5785b2c3b6aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“¥ Loading frames from videos...\n",
            "âœ… Loaded 12 frames for training\n",
            "Epoch 1: Loss=0.9998\n",
            "Epoch 2: Loss=0.0806\n",
            "Epoch 3: Loss=0.0901\n",
            "Epoch 4: Loss=0.0018\n",
            "Epoch 5: Loss=0.0004\n",
            "ðŸ’¾ Model saved as cnn_classifier.pt\n",
            "ðŸŽ¥ Video created at test_video.mp4\n",
            "âœ… Final Prediction for test_video.mp4: weeds\n"
          ]
        }
      ],
      "source": [
        "#!/usr/bin/env python3\n",
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import cv2\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import models, transforms\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from PIL import Image\n",
        "\n",
        "# ===============================\n",
        "#   Load frames from training videos\n",
        "# ===============================\n",
        "def load_frames_from_videos(base_dir, transform, classes, frame_skip=10):\n",
        "    data, labels = [], []\n",
        "    for idx, cls in enumerate(classes):\n",
        "        class_dir = os.path.join(base_dir, cls)\n",
        "        for video_file in os.listdir(class_dir):\n",
        "            # âœ… accept .avi or .mp4\n",
        "            if not (video_file.endswith(\".avi\") or video_file.endswith(\".mp4\")):\n",
        "                continue\n",
        "            video_path = os.path.join(class_dir, video_file)\n",
        "            cap = cv2.VideoCapture(video_path)\n",
        "            frame_count = 0\n",
        "            while True:\n",
        "                ret, frame = cap.read()\n",
        "                if not ret:\n",
        "                    break\n",
        "                if frame_count % frame_skip == 0:  # sample frames\n",
        "                    img = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
        "                    img_tensor = transform(img)\n",
        "                    data.append(img_tensor)\n",
        "                    labels.append(idx)\n",
        "                frame_count += 1\n",
        "            cap.release()\n",
        "    return torch.stack(data), torch.tensor(labels)\n",
        "\n",
        "# ===============================\n",
        "#   Training\n",
        "# ===============================\n",
        "def train_main_from_videos():\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "    ])\n",
        "\n",
        "    # âœ… point to crops/ and weeds/ subdirs\n",
        "    classes = [\"crops\", \"weeds\"]\n",
        "    print(\"Loading frames from videos...\")\n",
        "    data, labels = load_frames_from_videos(\"/content/sample_data\", transform, classes)\n",
        "\n",
        "    dataset = TensorDataset(data, labels)\n",
        "    loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "    print(f\"Loaded {len(dataset)} frames for training\")\n",
        "\n",
        "    # Model\n",
        "    model = models.resnet18(pretrained=True)\n",
        "    model.fc = nn.Linear(model.fc.in_features, len(classes))\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(5):  # adjust epochs as needed\n",
        "        total_loss = 0\n",
        "        for imgs, lbls in loader:\n",
        "            optimizer.zero_grad()\n",
        "            out = model(imgs)\n",
        "            loss = criterion(out, lbls)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "        print(f\"Epoch {epoch+1}: Loss={total_loss/len(loader):.4f}\")\n",
        "\n",
        "    torch.save(model.state_dict(), \"cnn_classifier.pt\")\n",
        "    print(\"ðŸ’¾ Model saved as cnn_classifier.pt\")\n",
        "\n",
        "# ===============================\n",
        "#   Convert test images â†’ video\n",
        "# ===============================\n",
        "def build_video_from_images_main(images_glob, out_path, fps=5, width=640, height=480):\n",
        "    img_files = sorted(glob.glob(images_glob))\n",
        "    if not img_files:\n",
        "        raise ValueError(\"No images found!\")\n",
        "\n",
        "    fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
        "    out = cv2.VideoWriter(out_path, fourcc, fps, (width, height))\n",
        "\n",
        "    for img_file in img_files:\n",
        "        img = cv2.imread(img_file)\n",
        "        if img is None:\n",
        "            continue\n",
        "        img = cv2.resize(img, (width, height))\n",
        "        out.write(img)\n",
        "    out.release()\n",
        "    print(f\"ðŸŽ¥ Video created at {out_path}\")\n",
        "\n",
        "# ===============================\n",
        "#   Testing on video\n",
        "# ===============================\n",
        "def test_on_video_main(video_path, ckpt_path, classes=[\"crops\", \"weeds\"]):\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "    ])\n",
        "\n",
        "    # Load trained model\n",
        "    model = models.resnet18(pretrained=True)\n",
        "    model.fc = nn.Linear(model.fc.in_features, len(classes))\n",
        "    model.load_state_dict(torch.load(ckpt_path, map_location=torch.device(\"cpu\")))\n",
        "    model.eval()\n",
        "\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    preds = []\n",
        "\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        img = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
        "        img_tensor = transform(img).unsqueeze(0)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            out = model(img_tensor)\n",
        "            _, pred = torch.max(out, 1)\n",
        "            preds.append(pred.item())\n",
        "\n",
        "    cap.release()\n",
        "\n",
        "    # Majority vote across frames\n",
        "    final_class = classes[max(set(preds), key=preds.count)]\n",
        "    print(f\"âœ… Final Prediction for {video_path}: {final_class}\")\n",
        "    return final_class\n",
        "\n",
        "# ===============================\n",
        "#   Main Execution\n",
        "# ===============================\n",
        "if __name__ == \"__main__\":\n",
        "    # 1. Train model on training videos\n",
        "    train_main_from_videos()\n",
        "\n",
        "    # 2. Convert test images â†’ video\n",
        "    build_video_from_images_main(\n",
        "        images_glob=\"/content/sample_data/test_img/*.JPG\",\n",
        "        out_path=\"test_video.mp4\",\n",
        "        fps=5,\n",
        "        width=640,\n",
        "        height=480\n",
        "    )\n",
        "\n",
        "    # 3. Test on new video\n",
        "    test_on_video_main(\n",
        "        video_path=\"test_video.mp4\",\n",
        "        ckpt_path=\"cnn_classifier.pt\"\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SDvGVP6BkTMW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}